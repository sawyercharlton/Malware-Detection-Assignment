import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import time
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler

# Load the dataset
file_path = './dataset.csv'
data = pd.read_csv(file_path)

# Extract information from the dataset
num_instances = data.shape[0]
num_features = data.shape[1] - 1  # since the label column is among the features
class_counts = data.iloc[:, 2].value_counts()  # label column is the third column

# print(f"Number of instances: {num_instances}")
# print(f"Number of features: {num_features}")
# print(f"Class distribution:\n{class_counts}")

# Perform EDA
# print("\ndata.columns:\n", data.columns)
# print("\ndata.describe(): \n", data.describe())
# print("\ndata.head(): \n", data.head())
# print("\ndata.isnull().sum(): \n", data.isnull().sum())

# corrMatrix = data.corr()
# sns.heatmap(corrMatrix, annot=True)
# plt.show()

X = data.drop(["hash","classification",'vm_truncate_count','shared_vm','exec_vm','nvcsw','maj_flt','utime'],axis=1)
y = data["classification"]
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)
# y = y.map({'benign':0, 'malware':1})

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
# print(f"Training set size: {X_train.shape[0]}")
# print(f"Testing set size: {X_test.shape[0]}")

# Data normalization
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# Initialize classifiers
classifiers = {
    "RandomForest": RandomForestClassifier(),
    "SVM": SVC(),
    "LogisticRegression": LogisticRegression()
}

# Train classifiers
for name, clf in classifiers.items():
    start_time = time.time()
    clf.fit(X_train, y_train)
    end_time = time.time()
    print(f"{name} training time: {end_time - start_time:.4f} seconds")

# Evaluate classifiers and generate confusion matrices
results = {}
for name, clf in classifiers.items():
    y_pred = clf.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)
    results[name] = {"confusion_matrix": cm, "report": report}

    print(f"\n{name} Classification Report:\n", classification_report(y_test, y_pred))
    sns.heatmap(cm, annot=True, fmt='d')
    plt.title(f'{name} Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Compare processing times
training_times = []
for name, clf in classifiers.items():
    start_time = time.time()
    clf.fit(X_train, y_train)
    end_time = time.time()
    training_times.append((name, end_time - start_time))

training_times.sort(key=lambda x: x[1])
print("\nClassifier Training Times (in seconds):")
for name, t in training_times:
    print(f"{name}: {t:.4f}")

# Optionally, visualize the training times
names, times = zip(*training_times)
plt.barh(names, times)
plt.xlabel('Time (seconds)')
plt.title('Classifier Training Times')
plt.show()